{"cells":[{"metadata":{"_uuid":"97c5b0c88b0cacdb6d693feadeb6e99c38b8636e"},"cell_type":"markdown","source":"# TMDB movie binary classification"},{"metadata":{"_uuid":"4d24584f75a8b53dc2a0647856fb94e7f59f27eb"},"cell_type":"markdown","source":"![imglink](https://fortunedotcom.files.wordpress.com/2017/08/movies.gif)\n\n(Image taken from [imglink](https://fortunedotcom.files.wordpress.com/2017/08/movies.gif))"},{"metadata":{"_uuid":"93b544ccd15a8ad649f6ec1dac81430a1dc3c8f1"},"cell_type":"markdown","source":"# Introduction\n\nFrom TMDB movie dataset, I decide to make some simple binary classification for predicting a **nice movie** <br>or movie that will get a** good rating** before movie release <br>\nand try to explore, visualize and wrangling the dataset.<br> \n\n\nIn this kernel,\n\n - Simple Exploratory Data Analysis\n - Data wrangling\n - Create model (without tuning parameter)\n - Comparing model"},{"metadata":{"trusted":false,"_uuid":"4cf8a039470e480cc71d8e1685e93d6cfc4ad4b2"},"cell_type":"code","source":"import json\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # this is used for the plot the graph \nimport seaborn as sns # used for plot interactive graph.\n\n\nfrom numpy import median\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom pylab import rcParams\n\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c34c8ff3acdb1b8539e3c916dcd2f822063f245"},"cell_type":"markdown","source":"**** Change Format from json file  ****\n    \n  Credit >>  [getting imdb kernels working with tmdb data](https://www.kaggle.com/sohier/getting-imdb-kernels-working-with-tmdb-data/)"},{"metadata":{"trusted":false,"_uuid":"ffcfaf8140db704ea793fc0bdef0c3d1a09c9b77"},"cell_type":"code","source":"def load_tmdb_movies(path):\n    df = pd.read_csv(path)\n    df['release_date'] = pd.to_datetime(df['release_date']).apply(lambda x: x.date())\n    json_columns = ['genres', 'keywords', 'production_countries', 'production_companies', 'spoken_languages']\n    for column in json_columns:\n        df[column] = df[column].apply(json.loads)\n    return df\n\n\ndef load_tmdb_credits(path):\n    df = pd.read_csv(path)\n    json_columns = ['cast', 'crew']\n    for column in json_columns:\n        df[column] = df[column].apply(json.loads)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"11eb3c2210affc53cbc3d8549367dd3e7d173533"},"cell_type":"code","source":"# Columns that existed in the IMDB version of the dataset and are gone.\nLOST_COLUMNS = [\n    'actor_1_facebook_likes',\n    'actor_2_facebook_likes',\n    'actor_3_facebook_likes',\n    'aspect_ratio',\n    'cast_total_facebook_likes',\n    'color',\n    'content_rating',\n    'director_facebook_likes',\n    'facenumber_in_poster',\n    'movie_facebook_likes',\n    'movie_imdb_link',\n    'num_critic_for_reviews',\n    'num_user_for_reviews'\n                ]\n\n# Columns in TMDb that had direct equivalents in the IMDB version. \n# These columns can be used with old kernels just by changing the names\nTMDB_TO_IMDB_SIMPLE_EQUIVALENCIES = {\n    'budget': 'budget',\n    'genres': 'genres',\n    'revenue': 'gross',\n    'title': 'movie_title',\n    'runtime': 'duration',\n    'original_language': 'language',  # it's possible that spoken_languages would be a better match\n    'keywords': 'plot_keywords',\n    'vote_count': 'num_voted_users',\n                                         }\n\nIMDB_COLUMNS_TO_REMAP = {'imdb_score': 'vote_average'}\n\n\ndef safe_access(container, index_values):\n    # return a missing value rather than an error upon indexing/key failure\n    result = container\n    try:\n        for idx in index_values:\n            result = result[idx]\n        return result\n    except IndexError or KeyError:\n        return pd.np.nan\n\n\ndef get_director(crew_data):\n    directors = [x['name'] for x in crew_data if x['job'] == 'Director']\n    return safe_access(directors, [0])\n\n\ndef pipe_flatten_names(keywords):\n    return '|'.join([x['name'] for x in keywords])\n\n\ndef convert_to_original_format(movies, credits):\n    # Converts TMDb data to make it as compatible as possible with kernels built on the original version of the data.\n    tmdb_movies = movies.copy()\n    tmdb_movies.rename(columns=TMDB_TO_IMDB_SIMPLE_EQUIVALENCIES, inplace=True)\n    tmdb_movies['title_year'] = pd.to_datetime(tmdb_movies['release_date']).apply(lambda x: x.year)\n    # I'm assuming that the first production country is equivalent, but have not been able to validate this\n    tmdb_movies['country'] = tmdb_movies['production_countries'].apply(lambda x: safe_access(x, [0, 'name']))\n    tmdb_movies['language'] = tmdb_movies['spoken_languages'].apply(lambda x: safe_access(x, [0, 'name']))\n    tmdb_movies['director_name'] = credits['crew'].apply(get_director)\n    tmdb_movies['actor_1_name'] = credits['cast'].apply(lambda x: safe_access(x, [0, 'name']))\n    tmdb_movies['actor_2_name'] = credits['cast'].apply(lambda x: safe_access(x, [1, 'name']))\n    tmdb_movies['actor_3_name'] = credits['cast'].apply(lambda x: safe_access(x, [2, 'name']))\n    tmdb_movies['companies_1'] = tmdb_movies['production_companies'].apply(lambda x: safe_access(x, [0, 'name']))\n    tmdb_movies['companies_2'] = tmdb_movies['production_companies'].apply(lambda x: safe_access(x, [1, 'name']))\n    tmdb_movies['companies_3'] = tmdb_movies['production_companies'].apply(lambda x: safe_access(x, [2, 'name']))\n    tmdb_movies['genres'] = tmdb_movies['genres'].apply(pipe_flatten_names)\n    tmdb_movies['plot_keywords'] = tmdb_movies['plot_keywords'].apply(pipe_flatten_names)\n    return tmdb_movies","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3098278dd2bf52f6eec746a923e8262b84fe8c3e"},"cell_type":"markdown","source":"**** Read files ****"},{"metadata":{"trusted":true,"_uuid":"43e546e12c7e0510d92570c72af176d4c8c12ef4"},"cell_type":"code","source":"movies = load_tmdb_movies(\"../input/tmdb_5000_movies.csv\")\ncredits = load_tmdb_credits(\"../input/tmdb_5000_credits.csv\")\ndata =convert_to_original_format(movies, credits)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"0a4ce125e380a6f53e69e4c9d6b87bc79e781226"},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ce4c843c6a6894880ec34e8d55f95031b80cb1fd"},"cell_type":"code","source":"#missing data\ntotal = data.isnull().sum().sort_values(ascending=False)\npercent = (data.isnull().sum()/data.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51377007f67226d42838a61042ef3d112e093d68"},"cell_type":"markdown","source":"**Missing value around 64 % for homepage features**"},{"metadata":{"trusted":false,"_uuid":"bc71ba169d9b9136f6204a904babc74572b51e48"},"cell_type":"code","source":"data.drop(['homepage'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6667eaa6130ffea649b95b2f9b64f0e7d2023e66"},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{"trusted":false,"_uuid":"1ae158a5b16d69faf1961ec2555175fe7272a67e"},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"75026c4ba5dc5880db866ebb5aa7860ad580105d"},"cell_type":"markdown","source":"## Drop features that only know after movie release\n\n**Objective of this kernel is predict movie before it release**"},{"metadata":{"trusted":false,"_uuid":"21e0971dac14fd295b37907062dd52c36d27907d"},"cell_type":"code","source":"data.drop(['num_voted_users','gross','popularity'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false,"_uuid":"942c4c06f22381341bcf448661743d4692ba445a"},"cell_type":"code","source":"# Correlation matrix between numerical values\nplt.figure(figsize = (10,8))\ng = sns.heatmap(data[list(data)].corr(),annot=True, fmt = \".2f\", cmap = \"coolwarm\",linewidths= 0.01)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c8735edb28fc0419320fbde8ae7f0a6d192f116f"},"cell_type":"markdown","source":"**From heatmap**, \n             <br>we can notice that title_year and duration has an impact to vote_average score.\n            "},{"metadata":{"_uuid":"27a9fa6e71dc44b33dcd4c94f1e9600e5afa3d3f"},"cell_type":"markdown","source":"### Title_year and vote_average"},{"metadata":{"scrolled":false,"trusted":false,"_uuid":"995c9f97f9e04ef47bbc967943ef7438ac465de5"},"cell_type":"code","source":"plt.figure(figsize = (10,10))\nsns.jointplot(x=\"title_year\", y=\"vote_average\", data=data);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d423edf5a0180ba589373d36222a0546cd69193e"},"cell_type":"markdown","source":"** A lot of movie in our dataset was made between 2000 and 2017. **\n \n\n    many rows in our dataset contain 0 vote average and I decide to delete them"},{"metadata":{"trusted":false,"_uuid":"975e5e7227ee7d6d19a4bf14e2a9b8569ea5a006"},"cell_type":"code","source":"data = data[data['vote_average'] != 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9fa58d3b13a7ddb7a326236e0968622f4e7086ce"},"cell_type":"code","source":"plt.figure(figsize = (10,10))\nsns.regplot(x=\"title_year\", y=\"vote_average\", data=data);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58f7cb904fa083baa80236ec7d3d820737eedc8a"},"cell_type":"markdown","source":"**and seem like their avg vote_average are lower than old movie **"},{"metadata":{"_uuid":"0ce2c776a9967d8b332d8b616abdad164cfafbc7"},"cell_type":"markdown","source":"### duration and vote_average"},{"metadata":{"trusted":false,"_uuid":"504bf62cddf5af826efa397f8de9fa91f04ebbd6"},"cell_type":"code","source":"plt.figure(figsize = (10,10))\nsns.jointplot(x=\"duration\", y=\"vote_average\", data=data, color= 'Red');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4b551a64b1dfad2de4b3cfdf87c1ba3855b7f37"},"cell_type":"markdown","source":"** Most of directors decide to make 90-120 mins movie **\n\n    some movie in our data set has 0 duration and I think it not possible"},{"metadata":{"trusted":false,"_uuid":"c5824dafc0a46ff8ec74009ff391655685cb364c"},"cell_type":"code","source":"data = data[data['duration'] != 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"02ef5979923989ac10efa85c63d36036b7d896a7"},"cell_type":"code","source":"plt.figure(figsize = (10,10))\nsns.regplot(x=\"duration\", y=\"vote_average\", data=data, color= 'Red');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd85229f52fdcaf7965fab1f05a0b8fd450afa62"},"cell_type":"markdown","source":"**Long movie look like to get higher score than short movie **"},{"metadata":{"_uuid":"24bffdcbad0719505ddbadfa848f5c813b9410b1"},"cell_type":"markdown","source":"## Data wrangling\n     Because we have many useful features that can't use to create a model\n    Then we need to edit the data format\n"},{"metadata":{"trusted":false,"_uuid":"ce9a8ac510c5c3161dc948e1527f3bfb30a40656"},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"291b27b9eb96c3ed2b6f52fa1c7d83b9ae704453"},"cell_type":"markdown","source":"# As I said in this kernel name, this is binary classification kernel."},{"metadata":{"_uuid":"7b36b3fd5920f0d388569e6394aac53515b9e381"},"cell_type":"markdown","source":"## We need some target binary variable which is a criteria for seperate nice movie or not"},{"metadata":{"_uuid":"152b23553b0aa0ee34227d4f6854eda741c583a3"},"cell_type":"markdown","source":"*** For This kernel, I decide to declare nice movies as a movie which got vote_score more than vote_score mean ***"},{"metadata":{"trusted":false,"_uuid":"e9f8307c3b3d3a4e7af52a46fbf40f2032a57cd9"},"cell_type":"code","source":"data['vote_average'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"0bab7ec46816c29dd9f70fe45be077abcf04ffa5"},"cell_type":"code","source":"data['Nice'] = data['vote_average'].map(lambda s :1  if s >= data['vote_average'].mean() else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"32bd6295fc852dad8f9be320dd8fc688fd8ffc2e"},"cell_type":"code","source":"data.loc[:, ['vote_average', 'Nice']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"8b0d550350492455daa1ec2a797e0d17f7bac9c4"},"cell_type":"code","source":"rcParams['figure.figsize'] = 13,10","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"aeaca62973f1c6cd02291b793596bf9e6b20b94f"},"cell_type":"code","source":"data['Nice'].value_counts(sort = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f9533325215c002c795023aa683855e9a7e59d86"},"cell_type":"code","source":"# Data to plot\nlabels =[\"not\",\"nice movie\"]\nsizes = data['Nice'].value_counts(sort = False)\ncolors = [\"pink\",\"whitesmoke\"]\nexplode = (0.1,0)  # explode 1st slice\n \n# Plot\nplt.pie(sizes, explode=explode, labels=labels, colors=colors,\n        autopct='%1.1f%%', shadow=True, startangle=140,)\nplt.axis('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c9ea0e23f9454999472158c315f13277c28e2b3e"},"cell_type":"code","source":"#### 54.1% of movies in our dataset are nice movie","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ecba22103352ee0366cbfd4556f5d89482ae65e"},"cell_type":"markdown","source":"## Budget"},{"metadata":{"trusted":false,"_uuid":"f956f94eb4f893d54e67e92b2edb539591a91aa3"},"cell_type":"code","source":"# budget distibution \ng = sns.kdeplot(data.budget[(data[\"Nice\"] == 0) ], color=\"Red\", shade = True)\ng = sns.kdeplot(data.budget[(data[\"Nice\"] == 1) ], ax =g, color=\"Blue\", shade= True)\ng.set_xlabel(\"budget\")\ng.set_ylabel(\"Frequency\")\ng = g.legend([\"Not\",\"Nice\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"6979836314ea25df942db57bb1fc46d707056789"},"cell_type":"code","source":"import statistics\nsd = statistics.stdev(data.budget)\nmean = data.budget.mean()\nmax = data.budget.max()\nmin = data.budget.min()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3c40b4c6af0076bba6d9a533d983afd489946481"},"cell_type":"code","source":"# Create new feature of budget \n\ndata['VeryLowBud'] = data['budget'].map(lambda s: 1 if s < 10000000 else 0)\ndata['LowBud'] = data['budget'].map(lambda s: 1 if 10000000 <= s < mean else 0)\ndata['MedBud'] = data['budget'].map(lambda s: 1 if  mean <= s < mean+sd  else 0)\ndata['HighBud'] = data['budget'].map(lambda s: 1 if mean+sd <= s < 100000000 else 0)\ndata['VeryHighBud'] = data['budget'].map(lambda s: 1 if s >= 100000000 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"fc0dff4663e0d41aeb904d8c1948e27f13ae022b"},"cell_type":"code","source":"g = sns.factorplot(x=\"VeryLowBud\",y=\"Nice\",data=data,kind=\"bar\",palette = \"husl\")\ng = g.set_ylabels(\"Nice Probability\")\ng = sns.factorplot(x=\"LowBud\",y=\"Nice\",data=data,kind=\"bar\",palette = \"husl\")\ng = g.set_ylabels(\"Nice Probability\")\ng = sns.factorplot(x=\"MedBud\",y=\"Nice\",data=data,kind=\"bar\",palette = \"husl\")\ng = g.set_ylabels(\"Nice Probability\")\ng = sns.factorplot(x=\"HighBud\",y=\"Nice\",data=data,kind=\"bar\",palette = \"husl\")\ng = g.set_ylabels(\"Nice Probability\")\ng = sns.factorplot(x=\"VeryHighBud\",y=\"Nice\",data=data,kind=\"bar\",palette = \"husl\")\ng = g.set_ylabels(\"Nice Probability\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b30c1528bc58870333511947c41a3cf01cffaf3e"},"cell_type":"markdown","source":"## Title year "},{"metadata":{"trusted":false,"_uuid":"e300c69b87e447731f57232b05c266d3588b579f"},"cell_type":"code","source":"g = sns.factorplot(y=\"title_year\",x=\"Nice\",data=data,kind=\"violin\", palette = \"Set2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d3717c7f6d6e5402cc4d30b228dc8ca03459e18b"},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a67cab42f457ce05b79f98489af165822ec073ba"},"cell_type":"markdown","source":"## Duration"},{"metadata":{"trusted":false,"_uuid":"3bf41f1b10aa438703c3dac16fc7e1d8530c0043"},"cell_type":"code","source":"data = data[np.isfinite(data['duration'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"6f72cceb2b2febb5a82b9506d02d371997c5dec5"},"cell_type":"code","source":"# duration distibution \ng = sns.kdeplot(data.duration[(data[\"Nice\"] == 0) ], color=\"blueviolet\", shade = True)\ng = sns.kdeplot(data.duration[(data[\"Nice\"] == 1) ], ax =g, color=\"gold\", shade= True)\ng.set_xlabel(\"Duration\")\ng.set_ylabel(\"Frequency\")\ng = g.legend([\"Not\",\"Nice\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"556de48b64c10c3df97c5d8c5c0340e692cde727"},"cell_type":"code","source":"g = sns.factorplot(x=\"Nice\", y = \"duration\",data = data, kind=\"box\", palette = \"Set3\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a1c6bcc6eb58675349e3b65dcdcbfd56b8f97d5c"},"cell_type":"code","source":"# Create new feature of duration\n\ndata['ShortMovie'] = data['duration'].map(lambda s: 1 if s < 90 else 0)\ndata['NotTooLongMovie'] = data['duration'].map(lambda s: 1 if 90 <= s < 120 else 0)\ndata['LongMovie'] = data['duration'].map(lambda s: 1 if   s >= 120  else 0)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e77788213a242b63faed875dd755973d14c089ff"},"cell_type":"markdown","source":"## Genres "},{"metadata":{"trusted":false,"_uuid":"eec4f748f3cef0a3e0c385723b12a4ca044d20c2"},"cell_type":"code","source":"data['genres'].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"634f03f2e23841d274af92e6e92482a67c428ff9"},"cell_type":"markdown","source":"**Many genres in one movie is the first problem that we met !!**\n\n       It can't use even make some simple tree !!.\n         Then, I decide to make this column to binary format."},{"metadata":{"trusted":false,"_uuid":"b17e7120f176226c69713909f72de6304a1c93bc"},"cell_type":"code","source":"\ndef Obtain_list_Occurences(columnName):\n    # Obtaining a list of columnName\n    list_details = list(map(str,(data[columnName])))\n    listOcc = []\n    for i in data[columnName]:\n        split_genre = list(map(str, i.split('|')))\n        for j in split_genre:\n            if j not in listOcc:\n                listOcc.append(j)\n    return listOcc\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ca2751b6893bccc33ec6aadb469b31f2c5c98253"},"cell_type":"code","source":"genre = []\ngenre = Obtain_list_Occurences(\"genres\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"af24994bc3892d8117fe07a6fe921e8bfa5ef320"},"cell_type":"code","source":"for word in genre:\n    data[word] = data['genres'].map(lambda s: 1 if word in str(s) else 0)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"e3c730e4509725fc388650a50d611fa019ff7d40"},"cell_type":"code","source":"data.loc[:,'Action': 'Foreign'].head(5)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8e8a2122cc9b94861fb1bd6c5a951e359d52434"},"cell_type":"markdown","source":"**Oh!!, It's better ??**\n<br> but, we have anoter column that very similar to genre...\n<br> That is 'keyword'"},{"metadata":{"trusted":false,"_uuid":"d95bc5845adc309ca96754386ef62d93a6e6f907"},"cell_type":"code","source":"data['plot_keywords'].head(20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"08b94cb2ef0cf366078302d03b147bd3fd0b5533"},"cell_type":"markdown","source":"**But..** <br>It's has many keyword, How many keywords should I use."},{"metadata":{"_uuid":"454d66b0e4eeb942d80bc3a780ac62b3bf8ffd26"},"cell_type":"markdown","source":"Credit : https://www.kaggle.com/fabiendaniel/film-recommendation-engine"},{"metadata":{"trusted":false,"_uuid":"71469f2a29cadaca37c2ce70655f6770a04fbd60"},"cell_type":"code","source":"def count_word(df, ref_col, liste):\n    keyword_count = dict()\n    for s in liste: keyword_count[s] = 0\n    for liste_keywords in df[ref_col].str.split('|'):        \n        if type(liste_keywords) == float and pd.isnull(liste_keywords): continue        \n        for s in [s for s in liste_keywords if s in liste]: \n            if pd.notnull(s): keyword_count[s] += 1\n    #______________________________________________________________________\n    # convert the dictionary in a list to sort the keywords by frequency\n    keyword_occurences = []\n    for k,v in keyword_count.items():\n        keyword_occurences.append([k,v])\n    keyword_occurences.sort(key = lambda x:x[1], reverse = True)\n    return keyword_occurences, keyword_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"15efac0968cd42bf61893915ab4db9f3531dc465"},"cell_type":"code","source":"set_keywords = set()\nfor liste_keywords in data['plot_keywords'].str.split('|').values:\n    if isinstance(liste_keywords, float): continue  # only happen if liste_keywords = NaN\n    set_keywords = set_keywords.union(liste_keywords)\n#_________________________\n# remove null chain entry\nset_keywords.remove('')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"8d389d0d0d1e9f29a523504b0bc78dbe398d7de4"},"cell_type":"code","source":"keyword_occurences, dum = count_word(data, 'plot_keywords', set_keywords)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ec625e335f976af5ec5588ef8b75d0a7e7f9e63"},"cell_type":"markdown","source":"**Okays, I got the most 10 keywords that contains in our dataset **\n<br> Then, I use this Top 10 repeated keywords."},{"metadata":{"trusted":false,"_uuid":"d3725af53f5b5cabddd18c7791c6d6fd8d189c6e"},"cell_type":"code","source":"## Funtion to find top 10 in list\n\ndef TopTen(theList):\n    TopTen = list()\n\n    for i in range(0, 10):\n        TopTen.append(theList[i][0])\n    \n    return TopTen\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b13d304834711fbc90f2aad27faa45d9d5537417"},"cell_type":"code","source":"from wordcloud import WordCloud\n\ndef makeCloud(Dict,name,color):\n    words = dict()\n\n    for s in Dict:\n        words[s[0]] = s[1]\n\n        wordcloud = WordCloud(\n                      width=1500,\n                      height=750, \n                      background_color=color, \n                      max_words=50,\n                      max_font_size=500, \n                      normalize_plurals=False)\n        wordcloud.generate_from_frequencies(words)\n\n\n    fig = plt.figure(figsize=(12, 8))\n    plt.title(name)\n    plt.imshow(wordcloud)\n    plt.axis('off')\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"de6c59965e4a50b75addf5ba16d6307fd1ccad02"},"cell_type":"code","source":"makeCloud(keyword_occurences[0:15],\"Keywords\",\"White\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c361443be51a1fc5198888625b52fe7cf066d204"},"cell_type":"code","source":"for word in TopTen(keyword_occurences):\n    data[word] = data['plot_keywords'].map(lambda s: 1 if word in str(s) else 0)\n\n    \ndata.drop('plot_keywords',axis=1,inplace=True)\ndata.loc[:,'woman director':].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7485ae93c0c16241fac16a82bb3baf485a147972"},"cell_type":"markdown","source":"### Do the same way with Actor, Director and Company "},{"metadata":{"_uuid":"01a8b78347f90362f128ccad9d2689118f77ff38"},"cell_type":"markdown","source":"## Director"},{"metadata":{"trusted":false,"_uuid":"2eb9d690719a7972ce162cf6b39ae9a568a3e127"},"cell_type":"code","source":"data['director_name'].fillna('unknown',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f653148222dfceefd5a25e086544c31b4880eac8"},"cell_type":"code","source":"def to_frequency_table(data):\n    frequencytable = {}\n    for key in data:\n        if key in frequencytable:\n            frequencytable[key] += 1\n        else:\n            frequencytable[key] = 1\n    return frequencytable","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"cef00c2d10050e8be37008336eedf183c32727d9"},"cell_type":"code","source":"director_dic = to_frequency_table(data['director_name'])\ndirector_list = list(director_dic.items())\ndirector_list.sort(key=lambda tup: tup[1],reverse=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"35e2f67388c83c50243192d2a8da691e516ff880"},"cell_type":"code","source":"makeCloud(director_list[0:10],\"director\",\"whitesmoke\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7f5b51e0136b7d1892e67a6883f3f87c4fd82768"},"cell_type":"code","source":"for word in TopTen(director_list):\n    data[word] = data['director_name'].map(lambda s: 1 if word in str(s) else 0)\n\ndata.loc[:,'Steven Spielberg': ].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f0686455a1611bf0060ba16c069f648a13cd001"},"cell_type":"markdown","source":"## Actor"},{"metadata":{"_uuid":"47eec42533666988118cca762abd9e5ffb44ce83"},"cell_type":"markdown","source":"    In this dataset, it contain 3 actor_name columns and a lot of missing value for second and third actor\n    we need to combine it first"},{"metadata":{"trusted":false,"_uuid":"302e9a2719434bc0cf96113a739f46dfb024cea3"},"cell_type":"code","source":"data['actor_1_name'].fillna('unknown',inplace=True)\ndata['actor_2_name'].fillna('unknown',inplace=True)\ndata['actor_3_name'].fillna('unknown',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"2da8fa98326773cd404305e32435b12fe0f27aca"},"cell_type":"code","source":"data[['actor_1_name','actor_2_name','actor_3_name']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"1157f9ae3c2171a8169ef25e90dc6bbc15158d14"},"cell_type":"code","source":"data['actors_name'] = data[['actor_1_name', 'actor_2_name','actor_3_name']].apply(lambda x: '|'.join(x), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9ca6b281c5afbddcaa2ac157939e594e88683393"},"cell_type":"code","source":"data[['actors_name']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"dc8abd000e04af04db2d3984c8d4d2d4d4a91898"},"cell_type":"code","source":"actor = []\nactor = Obtain_list_Occurences(\"actors_name\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d2e10642b37044b6f8c8f226ee389d30fb3b8c7b"},"cell_type":"code","source":"for word in actor:\n    data[word] = data['actors_name'].map(lambda s: 1 if word in str(s) else 0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"779668fc602379e36d39b1d6e49c2da0db85e6f4"},"cell_type":"markdown","source":"## Company\n\n    do the same with method which we do in actor"},{"metadata":{"trusted":false,"_uuid":"2237a56f21538bcc9f7624b1e8761f711cc3ee49"},"cell_type":"code","source":"data['companies_1'].fillna('unknown',inplace=True)\ndata['companies_2'].fillna('unknown',inplace=True)\ndata['companies_3'].fillna('unknown',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"0cb822331eaac910258f0976e2e88ba88944f0ce"},"cell_type":"code","source":"data['companies_name'] = data[['companies_1', 'companies_2','companies_3']].apply(lambda x: '|'.join(x), axis=1)\ncompany = []\ncompany = Obtain_list_Occurences(\"companies_name\")\n\nfor word in company:\n    data[word] = data['companies_name'].map(lambda s: 1 if word in str(s) else 0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba0620ba73353ad42e9d0c6c2cd159eca2a029e2"},"cell_type":"markdown","source":"   **Let's delete data that not effect to model or already have a same information but in tidy format column**"},{"metadata":{"trusted":false,"_uuid":"311b1f397927dc39bbe89bab2b2a3e9ba7794a07"},"cell_type":"code","source":"data.drop(['id','budget','original_title','overview','spoken_languages','production_companies','production_countries','release_date','status',\n          'tagline','movie_title','vote_average','language','director_name','actor_1_name','actor_2_name','actor_3_name',\n          'companies_1','companies_2','companies_3','country','genres','duration','actors_name','companies_name'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false,"_uuid":"e45e1bf0aee637649bec6329971c0a73e0af8bb7"},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8a10ec05a413fa13c5381d3fac5f45a43f77931"},"cell_type":"markdown","source":"### Check missing data"},{"metadata":{"trusted":false,"_uuid":"24d401364b4820c68e5e23f016be25d3cceda3dd"},"cell_type":"code","source":"total = data.isnull().sum().sort_values(ascending=False)\npercent = (data.isnull().sum()/data.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d62740f004d91ddc932def7d9a4a8e27d23b895"},"cell_type":"markdown","source":"#  Create model step "},{"metadata":{"_uuid":"c1cfceb867a47f13a4e232bf4ea9898ba7a06aa8"},"cell_type":"markdown","source":"    Split data to train and test set"},{"metadata":{"trusted":false,"_uuid":"82d6ee69c946ca51dfd2c1803fc9728af178b5b9"},"cell_type":"code","source":"data['is_train'] = np.random.uniform(0, 1, len(data)) <= .75\n\n# View the top 5 rows\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5420bb6cbda7b935532e7db048d1cff14e2695ea"},"cell_type":"code","source":"# Create two new dataframes, one with the training rows, one with the test rows\ntrain, test = data[data['is_train']==True], data[data['is_train']==False]\n\ntrain.drop(['is_train'], axis=1, inplace=True)\ntest.drop(['is_train'], axis=1, inplace=True)\n\ntrain[\"Nice\"] = train[\"Nice\"].astype(int)\n\nY_train = train[\"Nice\"]\nX_train = train.drop(labels = [\"Nice\"],axis = 1)\nY_test = test[\"Nice\"]\nX_test = test.drop(labels = [\"Nice\"],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ece5352c5334a9bdc1440523e527c9062f6a2b42"},"cell_type":"markdown","source":"** I split our dataset to 2 part **\n<br> *75% for train dataset *\n<br> *and 25% for test dataset *"},{"metadata":{"trusted":false,"_uuid":"4c351184c8a1989f6a3cbce2a779d26c8dca530d"},"cell_type":"code","source":"print(len(train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"fc6928c5186a75e8e98b22f52d5ceaa663cf828e"},"cell_type":"code","source":"print(len(test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d0be0384f204649fd6ee7584c0dceafdeb0a586"},"cell_type":"markdown","source":"## Decision Tree"},{"metadata":{"trusted":false,"_uuid":"c23873c3a1927ed9322c92ac472f0a45fb8c794c"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\nclf = DecisionTreeClassifier()\nclf.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fca6417ccb40ec268c7ca6d898f79e7e5462147a"},"cell_type":"markdown","source":"** Ok, test model performance by cross validation method **"},{"metadata":{"trusted":false,"_uuid":"dcacf63797d9b451c0b5ce7ecaba267f72b05303"},"cell_type":"code","source":"from sklearn.model_selection import  cross_val_score\n\nc_dec = cross_val_score(clf, X_train, Y_train, cv=10)\nc_dec.mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f52b808d0bf7b07dea210c21e5afe734882dba93"},"cell_type":"markdown","source":"**However, why not try with test dataset**"},{"metadata":{"trusted":false,"_uuid":"0289d70f0789a0ebd0c0a97cf644d5806819cb8f"},"cell_type":"code","source":"result = clf.predict_proba(X_test)[:]\ntest_result = np.asarray(Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"65a448e3e63cf2f95c726453be271fe9cd1c29cc"},"cell_type":"code","source":"Dec_result = pd.DataFrame(result[:,1])\nDec_result['Predict'] = Dec_result[0].map(lambda s: 1 if s >= 0.6  else 0)\nDec_result['testAnswer'] = pd.DataFrame(test_result)\n\nDec_result['Correct'] = np.where((Dec_result['Predict'] == Dec_result['testAnswer'])\n                     , 1, 0)\nDec_result.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"eaa5f8ca87a2eb52debd6ace50a6f2e51731dc49"},"cell_type":"code","source":"Dec_result['Correct'].mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"476353222e4516542aa869f1ac182668b2ef18eb"},"cell_type":"markdown","source":"## Ok... Let, Create next models"},{"metadata":{"_uuid":"2e84eae84e1e7334633e7a19c920ece878aa5eb1"},"cell_type":"markdown","source":"## Try with another common classification algorithm"},{"metadata":{"_uuid":"c721d2f9c1e57a387c876ad3c09ec28b0ab820ff"},"cell_type":"markdown","source":"### K-Nearest Neighbors\n\n check with 60 neighbors"},{"metadata":{"trusted":false,"_uuid":"8e556d5eeeedb3d233a5a38dd890cc55aca6ad54"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors= 60 )\nknn.fit(X_train, Y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80c21f1f71fea454a4b5fd7aa69aa1c0bee5cbfb"},"cell_type":"markdown","source":"* Cross validation score"},{"metadata":{"trusted":false,"_uuid":"0eec48050565c8f418777c15516eef0855f3a9d0"},"cell_type":"code","source":"c_knn = cross_val_score(knn, X_train, Y_train, cv=10)\nc_knn.mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2532161d7b8cf4d7ea6038027e52b3f66f4f71bd"},"cell_type":"markdown","source":"* Test score"},{"metadata":{"trusted":false,"_uuid":"6f3d85f6ec3868533618d698ac755af2b93c93e5"},"cell_type":"code","source":"result = knn.predict_proba(X_test)[:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a4d29d52b7b28e263ecc1103017bf822a678557f"},"cell_type":"code","source":"knn_result = pd.DataFrame(result[:,1])\nknn_result['Predict'] = knn_result[0].map(lambda s: 1 if s >= 0.6  else 0)\nknn_result['testAnswer'] = pd.DataFrame(test_result)\n\nknn_result['Correct'] = np.where((knn_result['Predict'] == knn_result['testAnswer'])\n                     , 1, 0)\nknn_result.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"67d59193c42d7c444a12d84dd2aecc1b09fe6fcb"},"cell_type":"code","source":"knn_result['Correct'].mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"183cb994498416fc7fab9aeaa5cadf65c14a0292"},"cell_type":"markdown","source":"    In this case, K-NN gave a low accuracy, because of a lot of unimportant features. It made error in distance between neighbors "},{"metadata":{"_uuid":"f5c03d6f0b89b412a5b486eef03c88ef7f65e15f"},"cell_type":"markdown","source":"\n###  It's time to try with ensembel model"},{"metadata":{"_uuid":"d860561224a14b9810e86865cb1f2f719e6c2562"},"cell_type":"markdown","source":"## Random Forest"},{"metadata":{"trusted":false,"_uuid":"956721c5c414398b4704ee0d6eb84b72fe6fd1a1"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nRfclf = RandomForestClassifier()\nRfclf.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8881fe3e4d90386c027c3925549c70af5c596406"},"cell_type":"markdown","source":"** Ok finish for create simple randomforest. **\n<br> Let see the performance by cross validation method"},{"metadata":{"_uuid":"ac7b96196ef3e20f95f5398de2b0f42e1bc38701"},"cell_type":"markdown","source":"* Cross validation score"},{"metadata":{"trusted":false,"_uuid":"1ec03259864f2682aecddf8663de43e63fc135b6"},"cell_type":"code","source":"c_rf =  cross_val_score(Rfclf, X_train, Y_train, cv=10)\nc_rf.mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"92c8b2ac3b6c5162c4ccd68e5ba08fee19ed96b5"},"cell_type":"markdown","source":"* Test score"},{"metadata":{"trusted":false,"_uuid":"aa3fe91cb788eb5df36566c2daa66c26ea4c53c6"},"cell_type":"code","source":"result = Rfclf.predict_proba(X_test)[:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"2586d448cf161e12815c6461d45bde276e83ef17"},"cell_type":"code","source":"Rf_result = pd.DataFrame(result[:,1])\nRf_result['Predict'] = Rf_result[0].map(lambda s: 1 if s >= 0.6  else 0)\nRf_result['testAnswer'] = pd.DataFrame(test_result)\n\nRf_result['Correct'] = np.where((Rf_result['Predict'] == Rf_result['testAnswer'])\n                     , 1, 0)\nRf_result.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"1d3733ba7122de446561ba5ed0a8690e2ad10403"},"cell_type":"code","source":"Rf_result['Correct'].mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"488613d7ab2d548051a87f0344d296cc1325fd7c"},"cell_type":"markdown","source":"## Gradient Boosting "},{"metadata":{"trusted":false,"_uuid":"4044c1f056dbd83ac1bb6d4b372c64a5d841534d"},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier  \n\ngb = GradientBoostingClassifier()\ngb.fit(X_train, Y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"427bb925bc00bd441958ce9f947104e31bdf21bc"},"cell_type":"markdown","source":"* Cross validation score"},{"metadata":{"trusted":false,"_uuid":"54ca9f1747cfed377b2e0cc2034217d23edb1539"},"cell_type":"code","source":"c_gb = cross_val_score(gb, X_train, Y_train, cv=10)\nc_gb.mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ac1073cb747d880416cafe724bd340437c96cb0"},"cell_type":"markdown","source":"* Test score"},{"metadata":{"trusted":false,"_uuid":"6d85443171501b305e2a20852911e24c2db106ad"},"cell_type":"code","source":"result = gb.predict_proba(X_test)[:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"eb4728b1e8c92270397c063d81b690d798e5a781"},"cell_type":"code","source":"gb_result = pd.DataFrame(result[:,1])\ngb_result['Predict'] = gb_result[0].map(lambda s: 1 if s >= 0.6  else 0)\ngb_result['testAnswer'] = pd.DataFrame(test_result)\n\ngb_result['Correct'] = np.where((gb_result['Predict'] == gb_result['testAnswer'])\n                     , 1, 0)\ngb_result.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3cb7c09e88e1cd4ea50e9d6163c8c98c87d62ba1"},"cell_type":"code","source":"gb_result['Correct'].mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f1c8f0f106bbec67109e17f845928dbdfcb3111c"},"cell_type":"markdown","source":"** I think it's enough for my creating model step **"},{"metadata":{"_uuid":"10b85260914f8e048945e4cd14f53e89b13a19af"},"cell_type":"markdown","source":"# Conclusion model performance\n    \n        by using cross validation score"},{"metadata":{"trusted":false,"_uuid":"1ee0ccb8119d8009e55e4426222361043f03b008"},"cell_type":"code","source":"cv_means = []\ncv_means.append(c_dec.mean())\ncv_means.append(c_knn.mean())\ncv_means.append(c_rf.mean())\ncv_means.append(c_gb.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"eb64cba65a5bc1dcf52757f7e16e6bbde0cebb90"},"cell_type":"code","source":"cv_std = []\ncv_std.append(c_dec.std())\ncv_std.append(c_knn.std())\ncv_std.append(c_rf.std())\ncv_std.append(c_gb.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f782a322abcaf44ba437a04c67dc77838b698b30"},"cell_type":"code","source":"res1 = pd.DataFrame({\"ACC\":cv_means,\"Std\":cv_std,\"Algorithm\":[\"DecisionTree\",\"K-Nearest Neighbors\",\"Random Forest\",\"Gradient Boosting\"]})\nres1[\"Type\"]= \"CrossValid\"\ng = sns.barplot(\"ACC\",\"Algorithm\",data = res1, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\ng.set_xlabel(\"Mean Accuracy\")\ng = g.set_title(\"Cross validation scores\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f14ec046a97e8b14d539d90495f382c4553181d"},"cell_type":"markdown","source":"## Model Test "},{"metadata":{"trusted":false,"_uuid":"3ca0e0553969e70e7143798cc33575886bdfc85f"},"cell_type":"code","source":"tv_means = []\ntv_means.append(Dec_result['Correct'].mean())\ntv_means.append(knn_result['Correct'].mean())\ntv_means.append(Rf_result['Correct'].mean())\ntv_means.append(gb_result['Correct'].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"2d57bf8d7b11f528996579a122a6840f0a15aec6"},"cell_type":"code","source":"res2 = pd.DataFrame({\"ACC\":tv_means,\"Algorithm\":[\"DecisionTree\",\"K-Nearest Neighbors\",\"Random Forest\",\"Gradient Boosting\"]})\nres2['Type'] = \"Test\";\n\ng = sns.barplot(\"ACC\",\"Algorithm\",data = res2, palette=\"Set2\",orient = \"h\")\ng.set_xlabel(\"Mean Accuracy\")\ng = g.set_title(\"Test scores\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"63eb3aad4e3bedb8b99c316f4f7f323ea654f488"},"cell_type":"code","source":"res = pd.concat([res1,res2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a9228005c8b3daed8f6970959bde46435ff159ba"},"cell_type":"code","source":"g = sns.factorplot(x='Algorithm', y='ACC', hue='Type',palette=\"coolwarm\", data=res, kind='bar')\ng.set_xticklabels(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ccde5a82cdc4b210d0000f36cce36aaf0e625e16"},"cell_type":"markdown","source":"# Ok let check the feature importance\n## How many weight in each feature that each tree model give."},{"metadata":{"trusted":false,"_uuid":"393adc33fcaf52628277790d764ab9a4625dd66a"},"cell_type":"code","source":"dec_fea = pd.DataFrame(clf.feature_importances_)\ndec_fea[\"name\"] = list(X_train) \ndec_fea.sort_values(by=0, ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"8ec87a01818f0d661400588e0f62d46fc60025f3"},"cell_type":"code","source":"g = sns.barplot(0,\"name\",data = dec_fea.sort_values(by=0, ascending=False)[0:10], palette=\"Set2\",orient = \"h\")\ng.set_xlabel(\"Weight\")\ng = g.set_title(\"Decision Tree\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"35b377a34a0e028ad4e2849affc072d83c5d5887"},"cell_type":"code","source":"rf_fea = pd.DataFrame(Rfclf.feature_importances_)\nrf_fea[\"name\"] = list(X_train) \nrf_fea.sort_values(by=0, ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a5ef68c409f3b64a8d37711fce1553a774f35aac"},"cell_type":"code","source":"g = sns.barplot(0,\"name\",data = rf_fea.sort_values(by=0, ascending=False)[0:10], palette=\"Set2\",orient = \"h\")\ng.set_xlabel(\"Weight\")\ng = g.set_title(\"Random Forest\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ef2e881b6a24e1ef744ee8dab6dd3aaa41508b1c"},"cell_type":"code","source":"gb_fea = pd.DataFrame(gb.feature_importances_)\ngb_fea[\"name\"] = list(X_train) \ngb_fea.sort_values(by=0, ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"646c19beb63408ec36c236f919829b8efa8bbeb6"},"cell_type":"code","source":"g = sns.barplot(0,\"name\",data = gb_fea.sort_values(by=0, ascending=False)[0:10], palette=\"Set2\",orient = \"h\")\ng.set_xlabel(\"Weight\")\ng = g.set_title(\"Gradient Boosting\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71966a7708f230e83373af3a7f8b5ef9a960d133"},"cell_type":"markdown","source":"## How will it affect accuracy\n### if I combine Top 3 performance models together by voting prediction"},{"metadata":{"_uuid":"74e2f56418ed01607b5259605f2ce9de3f7b66ef"},"cell_type":"markdown","source":"## Hard Voting"},{"metadata":{"trusted":false,"_uuid":"6e8a08cc295e149d2672f024cc027a0dbc9d6f3c"},"cell_type":"code","source":"voting = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e2341d46c66f30b119e742a9a8e19832004b4b94"},"cell_type":"code","source":"voting[\"knn\"] =knn_result['Predict']\nvoting[\"GB\"] = gb_result['Predict']\nvoting[\"RF\"] = Rf_result['Predict']\nvoting['sum'] = voting.sum(axis=1)\n\nvoting['Predict'] = voting['sum'].map(lambda s: 1 if s >= 2 else 0)\n\nvoting['testAnswer'] = pd.DataFrame(test_result)\n\nvoting['Correct'] = np.where((voting['Predict'] == voting['testAnswer'])\n                     , 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"bdbab928622e51ffa117022d089d6a0c198041dc"},"cell_type":"code","source":"voting.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"0c6bd27aded99dbb630b03bbad95fe8a0cb342e2"},"cell_type":"code","source":"voting['Correct'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"dd1a94cedec2ccc375f226654e5cd6dd61245b85"},"cell_type":"code","source":"# Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\n\nprint(confusion_matrix(voting['testAnswer'], voting['Predict']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5dfca3b93a5cc0814714bcf61c74610fa21bb053"},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(voting['testAnswer'], voting['Predict']))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d1dce75dca6091b1a22f629d187bc659c9f0b57"},"cell_type":"markdown","source":"**Thank you for reading until the end : )** \n\n      This is my first kernel. I will try to update new version\n    please vote or comment If you like it ^_^\n    I am new kaggler, If you have any suggestion let me know in comment."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}